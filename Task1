from lxml import html
import requests
from pprint import pprint
from fake_useragent import UserAgent
from lxml import etree

import csv


def auto_corrector(list_text):
    """Функция для удаления \xa0 из полученного ответа"""
    res_list = []

    for i in range(len(list_text)):
        res_list.append(list_text[i].replace('\xa0', '').lstrip())
    return res_list


ua = UserAgent()

fake_user = ua.random # создаю фейкового юзера

# Подготовка данных к скреппингу
header = {'user-agent': fake_user}
# Ссылку на доску обявлений по продаже мобильных телефонов
url = 'https://www.avito.ru/moskva/telefony/mobile-ASgBAgICAUSwwQ2I_Dc?context=H4sIAAAAAAAA_wFRAK7_YToyOntzOjg6ImZyb21QYWdlIjtzOjE0OiJjYXRlZ29yeVdpZGdldCI7czo5OiJmcm9tX3BhZ2UiO3M6MTQ6ImNhdGVnb3J5V2lkZ2V0Ijt9inXVTFEAAAA&f=ASgBAQECA0SwwQ2I_Dfyig6kgpQBoNkSpKKSAwFA6OsONPz92wL6_dsC~P3bAgFFxpoMFHsiZnJvbSI6NzAwMCwidG8iOjB9&s=172297_desc'

# использую verify=False так как часть работы делал с рабочего компьютера. И requests.get конфликтует с какими то программами админов если нет verify=False
resource = requests.get(url, headers = header, verify=False)

# Создаю dom страницы
dom = html.fromstring(resource.text)

# Передаю xpath карточки товара содержащая основную информацию
list_board = '//div[@class="iva-item-root-Se7z4 photo-slider-slider-ZccM3 iva-item-list-CLaiS iva-item-redesign-H4ow9 iva-item-responsive-GCo6h items-item-Reit3 items-listItem-rKPls js-catalog-item-enum"]'
items = dom.xpath(list_board)

result_list = []

for item in items:

    # плучаю наименование товара
    teg_of_name = ".//h3[@class='styles-module-root-s3nJ7 styles-module-root-s4tZ2 " \
                  "styles-module-size_l-j3Csw styles-module-size_l_compensated-trWgn " \
                  "styles-module-size_l-ai2ZG styles-module-ellipsis-A5gkK styles-module-weight_bold-Bh2pN " \
                  "stylesMarningNormal-module-root-_xKyG stylesMarningNormal-module-header-l-GrtnL']/text()"
    name = item.xpath(teg_of_name)


    # Получаю цену товара
    teg_of_price = ".//strong[@class='styles-module-root-iIeZo']/span//text()"
    price = item.xpath(teg_of_price)
    price = auto_corrector(price) # Удаляю \xa0 из данных

    # Получаю 1 описание
    teg_of_discription1 = './/p[@class="styles-module-root-s4tZ2 styles-module-size_s-nEvE8 styles-module-size_s-PDQal ' \
                         'stylesMarningNormal-module-root-_xKyG stylesMarningNormal-module-paragraph-s-HX94M"]//text()'
    discription1 = item.xpath(teg_of_discription1)[0]

    # Получаю 2 описание (более подробное)
    teg_of_discription2 = './/p[@class="styles-module-root-s4tZ2 styles-module-size_s-nEvE8 ' \
                          'styles-module-size_s_compensated-wyNaE styles-module-size_s-PDQal ' \
                          'styles-module-ellipsis-A5gkK stylesMarningNormal-module-root-_xKyG ' \
                          'stylesMarningNormal-module-paragraph-s-HX94M styles-module-noAccent-XIvJm ' \
                          'styles-module-root_bottom-x1f86 styles-module-margin-bottom_6-SOtsv"]//text()'
    discription2 = item.xpath(teg_of_discription2)[0]

    result_list.append([name[0], price, discription1, discription2]) # создаю список списков, в котором каждый элемент это список описывающий параметры обьявления

pprint(result_list)
with open('result.csv', 'w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)

    # Записываем каждую строку из result_list как отдельную запись в файл
    for row in result_list:
        writer.writerow(row)
